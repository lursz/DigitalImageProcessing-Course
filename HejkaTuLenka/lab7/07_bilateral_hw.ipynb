{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Filtracja Non-Local Means\n",
    "\n",
    "## Definicja\n",
    "\n",
    "Kolejny \"poziom wtajemniczenia\" w zagadnienie filtracji obrazów to metoda Non-Local Means (NLM).\n",
    "Została ona zaproponowana w pracy *A non-local algorithm for image denoising* autorstwa Antoni Buades, Bartomeu Coll, i Jean Michel Morel na konferencji CVPR w 2005 roku.\n",
    "\n",
    "Filtr NLM dany jest zależnością:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{I}(\\mathbf{x}) = \\sum_{\\mathbf{p} \\in V(\\mathbf{x})} w(\\mathbf{p},\\mathbf{x})I(\\mathbf{p})\n",
    "\\end{equation}\n",
    "\n",
    "gdzie:\n",
    "- $I$ - obraz wejściowy,\n",
    "- $\\hat{I}$ - obraz wyjściowy (przefiltrowany),\n",
    "- $\\mathbf{x}$ - współrzędne piksela obrazu,\n",
    "- $V(\\mathbf{x})$ - obszar poszukiwań piksela, dla którego przeprowadzana jest filtracja,\n",
    "- $w$ - waga punktu $\\mathbf{p}$ z obszaru poszukiwań.\n",
    "\n",
    "Wróćmy na chwilę do filtracji bilateralnej. Tam waga danego piksela z kontekstu zależała od dwóch czynników - odległości przestrzennej pomiędzy pikselami oraz różnicy w jasności/kolorze pomiędzy pikselami (tzw. przeciwdziedzina).\n",
    "Filtr NLM stanowi uogólnienie tej metody - do obliczania wag nie wykorzystuje się już pojedynczych pikseli ($\\mathbf{p}$ i $\\mathbf{x}$), a lokalne konteksty ($N(\\mathbf{p})$ i $N(\\mathbf{x})$).\n",
    "\n",
    "Waga $w$ dana jest następującą zależnością:\n",
    "\n",
    "\\begin{equation}\n",
    "w(\\mathbf{p},\\mathbf{x}) = \\frac{1}{Z(\\mathbf{x})}\\exp(-\\frac{|| v(N(\\mathbf{p})) - v(N(\\mathbf{x})) ||^2_{2}}{\\alpha \\sigma^2})\n",
    "\\end{equation}\n",
    "\n",
    "gdzie:\n",
    "- \\begin{equation}\n",
    "Z(\\mathbf{x}) = \\sum_{\\mathbf{p} \\in  V(\\mathbf{x})} \\exp(-\\frac{|| v(N(\\mathbf{p})) - v(N(\\mathbf{x})) ||^2_{2}}{\\alpha \\sigma^2})\n",
    "\\end{equation},\n",
    "- $|| \\cdot ||$ - jest normą $L_2$ odległości pomiędzy dwoma kontekstami,\n",
    "- $v$ oznacza mnożenie punktowe kontekstu $N$ przez dwuwymiarową maskę Gaussa o odpowiadających kontekstowi wymiarach,\n",
    "- $\\alpha$ > 0 - parametr sterujący filtracją,\n",
    "- $\\sigma$ - parametr szumu stacjonarnego występującego na obrazie (w przypadku szumu niestacjonarnego, parametr $\\sigma$ musi zostać dopasowany lokalnie tj. $\\sigma = \\sigma(\\mathbf{x})$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analiza działania\n",
    "\n",
    "Zastanówmy sie teraz jak działa filtra NLM. Najprościej to zrozumieć na rysunku.\n",
    "\n",
    "\n",
    "\n",
    "1. Dla rozważanego piksela $\\mathbf{x}$ definiujemy obszar poszukiwań $V(\\mathbf{x})$. Uwaga - obszar poszukiwań ($V$) jest jednostką większą niż otoczenie/kontekst ($N$).\n",
    "\n",
    "2. Następnie, dla każdego z pikseli $\\mathbf{p} \\in  V(\\mathbf{x})$ oraz samego $\\mathbf{x}$ definiujemy otoczenie/kontekst odpowiednio $N(\\mathbf{p})$ i $N(\\mathbf{x})$.\n",
    "\n",
    "3. Wracamy do równania definiującego wagę  $w(\\mathbf{p},\\mathbf{x})$, a konkretnie do wyrażenia $|| v(N(\\mathbf{p})) - v(N(\\mathbf{x})) ||$. Przeanalizujmy co ono oznacza. Mamy dwa otoczenia: $N(\\mathbf{p})$ i $N(\\mathbf{x})$. Każde z nich mnożymy przez odpowiadającą maskę Gaussa - funkcja $v$. Otrzymujemy dwie macierze, które odejmujemy od siebie punktowo. Następnie obliczamy kwadrat z normy ($L_2$ definiujemy jako $||X||_2 = \\sqrt{\\sum_k|X_k|^2}$. Otrzymujemy zatem jedną liczbę, która opisuje nam podobieństwo otoczeń pikseli $\\mathbf{x}$ i $\\mathbf{p}$. Mała wartość oznacza otoczenia zbliżone, duża - różniące się. Ponieważ, z dokładnością do stałych, liczba ta stanowi wykładnik funkcji $e^{-x}$, to ostatecznie waga jest zbliżona do 1 dla otoczeń podobnych, a szybko maleje wraz z malejącym podobieństwem kontekstów.\n",
    "\n",
    "4. Podsumowując. Jak wynika z powyższej analizy filtr NLM to taki filtr bilateralny, w którym zamiast pojedynczych pikseli porównuje się ich lokalne otoczenia. Wpływa to pozytywnie na jakość filtracji, niestety kosztem złożoności obliczeniowej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Implementacja\n",
    "\n",
    "W ramach zadania należy zaimplementować filtr NLM, ocenić jego działanie w porównaniu do filtra Gaussa i bilateralnego oraz dokonać pomiaru czasu obliczeń (dla trzech wymienionych metod).\n",
    "\n",
    "Jak już się zrozumie jak działa NLM, jego implementacja jest dość prosta.\n",
    "Wartość parametru $\\alpha$ należy dobrać eksperymentalnie.\n",
    "Nie należy także \"przesadzić\" z rozmiarem obszaru poszukiwań (np. 11x11) oraz kontekstu (5x5 lub 3x3).\n",
    "\n",
    "Wskazówki do implementacji:\n",
    "- algorytm sprowadza się do dwóch podwójnych pętli for: zewnętrzne po pikselach, wewnętrzne po kolejnych obszarach przeszukań,\n",
    "- przed realizacją trzeba przemyśleć problem pikseli brzegowych - de facto problemów jest kilka. Po pierwsze nie dla każdego piksela można wyznaczyć pełny obszar przeszukań (tu propozycja, aby filtrację przeprowadzać tylko dla pikseli z pełnym obszarem). Po drugie, ponieważ rozpatrujemy konteksty, to nawet dla piksela o \"pełnym\" obszarze przeszukań, będą istnieć piksele, dla których nie pełnych kontekstów (sugestia - powiększyć obszar przeszukać, tak aby zawierał konteksty). Ostatni problem jest bardziej techniczny/implementacyjny. Jeśli w kolejnych iteracjach \"jawnie\" wytniemy fragment o rozmiarach obszaru przeszukiwań, to znowu pojawi się problem brzegowy - tu można albo wyciąć nieco większy obszar, albo cały czas \"pracować\" na obrazie oryginalnym (\"żonglerka indeksami\").\n",
    "- warto sprawdzać indeksy i rozmiary \"wycinanych\" kontekstów,\n",
    "- wagi wyliczamy w trzech krokach:\n",
    "    - obliczenia dla $N(\\mathbf{x})$ + inicjalizacja macierzy na wagi,\n",
    "    - podwójna pętla, w której przeprowadzamy obliczenia dla kolejnych $N(\\mathbf{p})$ oraz wyliczamy wagi,\n",
    "    - normalizacja macierzy wag oraz końcowa filtracja obszaru w wykorzystaniem wag.\n",
    "- uwaga, obliczenia trochę trwają, nawet dla obrazka 256x256 i względnie niewielkich obszaru przeszukań i kontesktu.\n",
    "\n",
    "Efekt końcowy:\n",
    "- porównanie wyników metod: filtr Gaussa, filtr bilateralny oraz filtr NLM (2-3 zdania komentarza),\n",
    "- porównanie czasu działania powyższych metod (1 zdanie komentarza).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import math\n",
    "import os\n",
    "from scipy import signal\n",
    "import cv2\n",
    "import copy\n",
    "from numpy import linalg as LA\n",
    "import time\n",
    "\n",
    "if not os.path.exists(\"MR_data.mat\") :\n",
    "    !wget https://raw.githubusercontent.com/vision-agh/poc_sw/master/07_Bilateral/MR_data.mat --no-check-certificate\n",
    "        \n",
    "mat = loadmat('MR_data.mat')\n",
    "\n",
    "Input_1 = mat['I_noisy1']\n",
    "Input_2 = mat['I_noisy2']\n",
    "Input_3 = mat['I_noisy3']\n",
    "Input_4 = mat['I_noisy4']\n",
    "Input_0 = mat['I_noisefree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgaussian(size, sigma):\n",
    "     m = n = size\n",
    "     h, k = m//2, n//2\n",
    "     x, y = np.mgrid[-h:h+1, -k:k+1]\n",
    "     g = np.exp(-(x**2 + y**2)/(2*sigma**2))\n",
    "     return g /g.sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgaussian_bez(size, sigma):\n",
    "     m = n = size\n",
    "     h, k = m//2, n//2\n",
    "     x, y = np.mgrid[-h:h+1, -k:k+1]\n",
    "     g = np.exp(-(x**2 + y**2)/(2*sigma**2))\n",
    "     return g "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLM(img,window,area,alfa,sigma_square):\n",
    "    v=fgaussian(window,np.sqrt(sigma_square))\n",
    "    IConvolucja = img.copy()\n",
    "    (X,Y)=IConvolucja.shape\n",
    "    area_half = area//2\n",
    "    window_half = window//2\n",
    "    for i in range(0+area_half+window_half,X-area_half-window_half):\n",
    "        for j in range(0+area_half+window_half,Y-area_half-window_half):\n",
    "                i_minus=i-area_half-window_half\n",
    "                i_plus=i+area_half+window_half+1\n",
    "                j_minus=j-area_half-window_half\n",
    "                j_plus=j+area_half+window_half+1\n",
    "                obszar = img[i_minus:i_plus,j_minus:j_plus]\n",
    "                a,b = obszar.shape\n",
    "                x = [i,j]\n",
    "                w_px=0\n",
    "                Zx=0\n",
    "                new_pixel=0\n",
    "                for k in range(0+window_half,a-window_half):\n",
    "                    for l in range(0+window_half,b-window_half):\n",
    "                        N_p=obszar[k-window_half:k+window_half+1,l-window_half:l+window_half+1]\n",
    "                        N_x=img[i-window_half:i+window_half+1,j-window_half:j+window_half+1]\n",
    "                        v_Np = v*N_p\n",
    "                        v_Nx=v*N_x\n",
    "                        Xk = v_Np-v_Nx\n",
    "                        X__2 = np.sqrt((Xk**2).sum())\n",
    "                        wpx = np.exp((-(X__2**2))/(alfa*sigma_square))\n",
    "                        Zx = Zx + wpx\n",
    "                        new_pixel = new_pixel + wpx*obszar[k,l]\n",
    "                new_pixel=new_pixel/Zx\n",
    "                IConvolucja[i,j]=new_pixel\n",
    "    return IConvolucja         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_out(okno,filtr,variancy):\n",
    "    A,B = okno.shape\n",
    "    pixel=0\n",
    "    x = [A//2,B//2]\n",
    "    for i in range(A):\n",
    "        for j in range(B):\n",
    "            AB=[i,j]\n",
    "            \n",
    "            y=np.sqrt(((x[0]-AB[0])**2)+((x[1]-AB[1])**2))\n",
    "            gaus= np.exp(-(y**2)/(2*(variancy**2)))\n",
    "            pixel=pixel+gaus*okno[i,j]\n",
    "    pixel=pixel/filtr.sum()\n",
    "    return pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Samodzielna\n",
    "def convol(img,window,variancy):\n",
    "    filtr=fgaussian_bez(5,variancy)\n",
    "    IConv = img.copy()\n",
    "    (X,Y)=IConv.shape\n",
    "    polowa = window//2\n",
    "    for i in range(0+window//2,X-window//2):\n",
    "        for j in range(0+window//2,Y-window//2):\n",
    "            okno = IConv[i-polowa:i+polowa+1,j-polowa:j+polowa+1]\n",
    "            new_pixel=pixel_out(okno,filtr,variancy)\n",
    "            IConv[i,j]=new_pixel\n",
    "    return IConv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_out_2(okno,filtr,variancy,delta_r):\n",
    "    A,B = okno.shape\n",
    "    pixel=0\n",
    "    normalization=0\n",
    "    x = [A//2,B//2]\n",
    "    for i in range(A):\n",
    "        for j in range(B):\n",
    "            AB=[i,j]\n",
    "            \n",
    "            y=np.sqrt(((x[0]-AB[0])**2)+((x[1]-AB[1])**2))\n",
    "            gaus= np.exp(-(y**2)/(2*(variancy**2)))\n",
    "            \n",
    "            diff=np.abs(okno[A//2,B//2]-okno[i,j])\n",
    "            gaus_diff= np.exp(-(diff**2)/(2*(delta_r**2)))\n",
    "            \n",
    "            \n",
    "            pixel=pixel+gaus*gaus_diff*okno[i,j]\n",
    "            normalization+=gaus*gaus_diff\n",
    "    pixel=pixel/(normalization)\n",
    "    return pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Samodzielna\n",
    "def bilateral(img,window,variancy,delta_r):\n",
    "    filtr=fgaussian_bez(window,variancy)\n",
    "    IConvolucja = img.copy()\n",
    "    (X,Y)=IConvolucja.shape\n",
    "    polowa = window//2\n",
    "    for i in range(0+window//2,X-window//2):\n",
    "        for j in range(0+window//2,Y-window//2):\n",
    "            okno = IConvolucja[i-polowa:i+polowa+1,j-polowa:j+polowa+1]\n",
    "            new_pixel=pixel_out_2(okno,filtr,variancy,delta_r)\n",
    "            IConvolucja[i,j]=new_pixel\n",
    "    return IConvolucja\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do porównania zostanie użyty najbardziej zaszumiony obraz, czyli u mnie Input_2.\n",
    "\n",
    "Pozwoli to najlepiej zoobrazować różnice pomiędzy algorytmami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_NLM = time.time()\n",
    "test_NLM=NLM(Input_2,window=3,area=7,alfa=5,sigma_square=50)\n",
    "stop_NLM = time.time()\n",
    "time_past_NLM = stop_NLM - start_NLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Proszę sobie puścić bo nie przejdzie przez upla ze zdjęciami\\nf, ax1 = plt.subplots(2,2,figsize=(16,16))\\nax1[0,0].imshow(convolucja_2, \\'gray\\')\\nax1[0,0].set_title(\"Konwolucja - czas - {}\".format(time_past_conv))\\nax1[0,0].axis(\\'off\\')\\nax1[0,1].imshow(bilateralne_2, \\'gray\\')\\nax1[0,1].set_title(\"Filtracja bilateralna - czas - {}\".format(time_past_bilateral))\\nax1[0,1].axis(\\'off\\')\\nax1[1,0].imshow(test_NLM, \\'gray\\')\\nax1[1,0].set_title(\"Filtracja NLM - czas - {}\".format(time_past_NLM))\\nax1[1,0].axis(\\'off\\')\\nax1[1,1].imshow(Input_2, \\'gray\\')\\nax1[1,1].set_title(\"Oryginał\")\\nax1[1,1].axis(\\'off\\')\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window=5\n",
    "variancy=0.9\n",
    "\n",
    "delta_r=45\n",
    "variancy_1=3\n",
    "start_conv=time.time()\n",
    "convolucja_2=convol(Input_2,window,variancy)\n",
    "stop_conv=time.time()\n",
    "time_past_conv = stop_conv - start_conv\n",
    "start_bilateral=time.time()\n",
    "bilateralne_2=bilateral(Input_2,window,variancy_1,delta_r)\n",
    "stop_bilateral=time.time()\n",
    "time_past_bilateral = stop_bilateral - start_bilateral\n",
    "\n",
    "\"\"\"\n",
    "#Proszę sobie puścić bo nie przejdzie przez upla ze zdjęciami\n",
    "f, ax1 = plt.subplots(2,2,figsize=(16,16))\n",
    "ax1[0,0].imshow(convolucja_2, 'gray')\n",
    "ax1[0,0].set_title(\"Konwolucja - czas - {}\".format(time_past_conv))\n",
    "ax1[0,0].axis('off')\n",
    "ax1[0,1].imshow(bilateralne_2, 'gray')\n",
    "ax1[0,1].set_title(\"Filtracja bilateralna - czas - {}\".format(time_past_bilateral))\n",
    "ax1[0,1].axis('off')\n",
    "ax1[1,0].imshow(test_NLM, 'gray')\n",
    "ax1[1,0].set_title(\"Filtracja NLM - czas - {}\".format(time_past_NLM))\n",
    "ax1[1,0].axis('off')\n",
    "ax1[1,1].imshow(Input_2, 'gray')\n",
    "ax1[1,1].set_title(\"Oryginał\")\n",
    "ax1[1,1].axis('off')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać najlepszy wynik osiągnęła ostatnia metoda\n",
    "\n",
    "Udało jej się zlikwidować cały szum a jednocześnie krawędzie dalej są widoczne i odróżnialne\n",
    "\n",
    "Widać również że filtr bilateralny jest znacząco lepszy od filtru gaussa dzięki lepszemu zachowaniu występujących krawędzi\n",
    "\n",
    "Nie zmienia to faktu że każda kolejna metoda wykorzystuje coraz więcej zasobów i potrzebuje więcej pamięci\n",
    "\n",
    "Widać to idealnie w czasie wykonywania funkcji, która dla metody NLM trwa ponad 4 razy dłużej niż dla gaussa i około 2.5 raza dłużej niż dla filtracji bilateralnej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
