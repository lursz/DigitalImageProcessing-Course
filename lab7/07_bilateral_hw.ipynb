{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "k4hd7OaOFqYm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Filtracja Non-Local Means\n",
    "\n",
    "## Definicja\n",
    "\n",
    "Kolejny \"poziom wtajemniczenia\" w zagadnienie filtracji obrazów to metoda Non-Local Means (NLM).\n",
    "Została ona zaproponowana w pracy *A non-local algorithm for image denoising* autorstwa Antoni Buades, Bartomeu Coll, i Jean Michel Morel na konferencji CVPR w 2005 roku.\n",
    "\n",
    "Filtr NLM dany jest zależnością:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{I}(\\mathbf{x}) = \\sum_{\\mathbf{p} \\in V(\\mathbf{x})} w(\\mathbf{p},\\mathbf{x})I(\\mathbf{p})\n",
    "\\end{equation}\n",
    "\n",
    "gdzie:\n",
    "- $I$ - obraz wejściowy,\n",
    "- $\\hat{I}$ - obraz wyjściowy (przefiltrowany),\n",
    "- $\\mathbf{x}$ - współrzędne piksela obrazu,\n",
    "- $V(\\mathbf{x})$ - obszar poszukiwań piksela, dla którego przeprowadzana jest filtracja,\n",
    "- $w$ - waga punktu $\\mathbf{p}$ z obszaru poszukiwań.\n",
    "\n",
    "Wróćmy na chwilę do filtracji bilateralnej. Tam waga danego piksela z kontekstu zależała od dwóch czynników - odległości przestrzennej pomiędzy pikselami oraz różnicy w jasności/kolorze pomiędzy pikselami (tzw. przeciwdziedzina).\n",
    "Filtr NLM stanowi uogólnienie tej metody - do obliczania wag nie wykorzystuje się już pojedynczych pikseli ($\\mathbf{p}$ i $\\mathbf{x}$), a lokalne konteksty ($N(\\mathbf{p})$ i $N(\\mathbf{x})$).\n",
    "\n",
    "Waga $w$ dana jest następującą zależnością:\n",
    "\n",
    "\\begin{equation}\n",
    "w(\\mathbf{p},\\mathbf{x}) = \\frac{1}{Z(\\mathbf{x})}\\exp(-\\frac{|| v(N(\\mathbf{p})) - v(N(\\mathbf{x})) ||^2_{2}}{\\alpha \\sigma^2})\n",
    "\\end{equation}\n",
    "\n",
    "gdzie:\n",
    "- \\begin{equation}\n",
    "Z(\\mathbf{x}) = \\sum_{\\mathbf{p} \\in  V(\\mathbf{x})} \\exp(-\\frac{|| v(N(\\mathbf{p})) - v(N(\\mathbf{x})) ||^2_{2}}{\\alpha \\sigma^2})\n",
    "\\end{equation},\n",
    "- $|| \\cdot ||$ - jest normą $L_2$ odległości pomiędzy dwoma kontekstami,\n",
    "- $v$ oznacza mnożenie punktowe kontekstu $N$ przez dwuwymiarową maskę Gaussa o odpowiadających kontekstowi wymiarach,\n",
    "- $\\alpha$ > 0 - parametr sterujący filtracją,\n",
    "- $\\sigma$ - parametr szumu stacjonarnego występującego na obrazie (w przypadku szumu niestacjonarnego, parametr $\\sigma$ musi zostać dopasowany lokalnie tj. $\\sigma = \\sigma(\\mathbf{x})$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipnn3yBGFqYp"
   },
   "source": [
    "## Analiza działania\n",
    "\n",
    "Zastanówmy sie teraz jak działa filtra NLM. Najprościej to zrozumieć na rysunku.\n",
    "\n",
    "![Ilustracja NLM](https://raw.githubusercontent.com/vision-agh/poc_sw/master/07_Bilateral/nlm.png)\n",
    "\n",
    "1. Dla rozważanego piksela $\\mathbf{x}$ definiujemy obszar poszukiwań $V(\\mathbf{x})$. Uwaga - obszar poszukiwań ($V$) jest jednostką większą niż otocznie/kontekst ($N$).\n",
    "\n",
    "2. Następnie, dla każdego z pikseli $\\mathbf{p} \\in  V(\\mathbf{x})$ oraz samego $\\mathbf{x}$ definiujemy otocznie/kontekst odpowiednio $N(\\mathbf{p})$ i $N(\\mathbf{x})$.\n",
    "\n",
    "3. Wracamy do równania definiującego wagę  $w(\\mathbf{p},\\mathbf{x})$, a konkretnie do wyrażenia $|| v(N(\\mathbf{p})) - v(N(\\mathbf{x})) ||$. Przeanalizujmy co ono oznacza. Mamy dwa otoczenia: $N(\\mathbf{p})$ i $N(\\mathbf{x})$. Każde z nich mnożymy przez odpowiadającą maskę Gaussa - funkcja $v$. Otrzymujemy dwie macierze, które odejmujemy od siebie punktowo. Następnie obliczamy kwadrat z normy ($L_2$ definiujemy jako $||X||_2 = \\sqrt{\\sum_k|X_k|^2}$. Otrzymujemy zatem jedną liczbę, która opisuje nam podobieństwo otoczeń pikseli $\\mathbf{x}$ i $\\mathbf{p}$. Mała wartość oznacza otoczenia zbliżone, duża - różniące się. Ponieważ, z dokładnością do stałych, liczba ta stanowi wykładnik funkcji $e^{-x}$, to ostatecznie waga jest zbliżona do 1 dla otoczeń podobnych, a szybko maleje wraz z malejącym podobieństwem kontekstów.\n",
    "\n",
    "4. Podsumowując. Jak wynika z powyższej analizy filtr NLM to taki filtr bilateralny, w którym zamiast pojedynczych pikseli porównuje się ich lokalne otoczenia. Wpływa to pozytywnie na jakość filtracji, niestety kosztem złożoności obliczeniowej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdcd4-c8FqYr",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Implementacja\n",
    "\n",
    "W ramach zadania należy zaimplementować filtr NLM, ocenić jego działanie w porównaniu do filtra Gaussa i bilateralnego oraz dokonać pomiaru czasu obliczeń (dla trzech wymienionych metod).\n",
    "\n",
    "Jak już się zrozumie jak działa NLM, jego implementacja jest dość prosta.\n",
    "Wartość parametru $\\alpha$ należy dobrać eksperymentalnie.\n",
    "Nie należy także \"przesadzić\" z rozmiarem obszaru poszukiwań (np. 11x11) oraz kontekstu (5x5 lub 3x3).\n",
    "\n",
    "Wskazówki do implementacji:\n",
    "- algorytm sprowadza się do dwóch podwójnych pętli for: zewnętrzne po pikselach, wewnętrzne po kolejnych obszarach przeszukań,\n",
    "- przed realizacją trzeba przemyśleć problem pikseli brzegowych - de facto problemów jest kilka. Po pierwsze nie dla każdego piksela można wyznaczyć pełny obszar przeszukań (tu propozycja, aby filtrację przeprowadzać tylko dla pikseli z pełnym obszarem). Po drugie, ponieważ rozpatrujemy konteksty, to nawet dla piksela o \"pełnym\" obszarze przeszukań, będą istnieć piksele, dla których nie pełnych kontekstów (sugestia - powiększyć obszar przeszukać, tak aby zawierał konteksty). Ostatni problem jest bardziej techniczny/implementacyjny. Jeśli w kolejnych iteracjach \"jawnie\" wytniemy fragment o rozmiarach obszaru przeszukiwań, to znowu pojawi się problem brzegowy - tu można albo wyciąć nieco większy obszar, albo cały czas \"pracować\" na obrazie oryginalnym (\"żonglerka indeksami\").\n",
    "- warto sprawdzać indeksy i rozmiary \"wycinanych\" kontekstów,\n",
    "- wagi wyliczamy w trzech krokach:\n",
    "    - obliczenia dla $N(\\mathbf{x})$ + inicjalizacja macierzy na wagi,\n",
    "    - podwójna pętla, w której przeprowadzamy obliczenia dla kolejnych $N(\\mathbf{p})$ oraz wyliczamy wagi,\n",
    "    - normalizacja macierzy wag oraz końcowa filtracja obszaru w wykorzystaniem wag.\n",
    "- uwaga, obliczenia trochę trwają, nawet dla obrazka 256x256 i względnie niewielkich obszaru przeszukań i kontesktu.\n",
    "\n",
    "Efekt końcowy:\n",
    "- porównanie wyników metod: filtr Gaussa, filtr bilateralny oraz filtr NLM (2-3 zdania komentarza),\n",
    "- porównanie czasu działania powyższych metod (1 zdanie komentarza).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T15:16:45.005389677Z",
     "start_time": "2023-11-20T15:16:44.941038045Z"
    },
    "id": "yd6FHw0uFqYs",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import requests\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.io import loadmat\n",
    "import math\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/vision-agh/poc_sw/master/07_Bilateral/\"\n",
    "\n",
    "fileNames = [\"MR_data.mat\"]\n",
    "for fileName in fileNames:\n",
    "    if not os.path.exists(fileName):\n",
    "        r = requests.get(url + fileName, allow_redirects=True)\n",
    "        open(fileName, \"wb\").write(r.content)\n",
    "\n",
    "mat = loadmat(fileNames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T15:10:35.246743961Z",
     "start_time": "2023-11-20T15:10:34.253809057Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 5, figsize=(25, 5))\n",
    "\n",
    "for ax, fn in zip(axs, [\"I_noisefree\", \"I_noisy1\", \"I_noisy2\", \"I_noisy3\", \"I_noisy4\"]):\n",
    "    ax.imshow(mat[fn], \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T15:10:35.247123358Z",
     "start_time": "2023-11-20T15:10:35.246080108Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fgaussian(size, sigma: float):\n",
    "    m = n = size\n",
    "    h, k = m // 2, n // 2\n",
    "    x, y = np.mgrid[-h : h + 1, -k : k + 1]\n",
    "    g = np.exp(-(x**2 + y**2) / (2 * sigma**2))\n",
    "    return g / g.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T15:36:55.200133110Z",
     "start_time": "2023-11-20T15:35:12.689828943Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def non_local_means(img, v:int, n: int, alpha: float, sigma: float):\n",
    "    img = img.astype(np.float64)\n",
    "    v += n // 2 * 2  \n",
    "    call_gaus = lambda x: fgaussian(n, sigma) * x\n",
    "    image = np.zeros(img.shape)\n",
    "    for x in range(v // 2, img.shape[0] - v // 2):\n",
    "        for y in range(v // 2, img.shape[1] - v // 2):\n",
    "\n",
    "            V = img[x - v // 2 : x + v // 2 + 1, y - v // 2 : y + v // 2 + 1]\n",
    "            Window = np.array([])\n",
    "            Nx = img[x - n // 2 : x + n // 2 + 1, y - n // 2 : y + n // 2 + 1]\n",
    "\n",
    "            for i in range(n // 2, V.shape[0] - n // 2):\n",
    "                for j in range(n // 2, V.shape[1] - n // 2):\n",
    "                    \n",
    "                    Np = V[i - n // 2 : i + n // 2 + 1, j - n // 2 : j + n // 2 + 1]\n",
    "                    Wexp = np.exp(\n",
    "                        -np.sum((call_gaus(Np) - call_gaus(Nx)) ** 2) / (alpha * sigma**2)\n",
    "                    )\n",
    "                    Window = np.append(Window, Wexp)\n",
    "            W = Window / np.sum(Window)\n",
    "            I = V[n // 2 : -(n // 2), n // 2 : -(n // 2)]\n",
    "            image[x, y] = np.sum(W.reshape(I.shape) * I)\n",
    "    max_val = max(image.flatten())\n",
    "\n",
    "    return (image / max_val * 255).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T15:20:39.959485254Z",
     "start_time": "2023-11-20T15:20:39.955551060Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classic_convolution(img, window: int, sigma: float):\n",
    "    kernel = fgaussian(window, sigma)\n",
    "    image = img.copy()\n",
    "\n",
    "    image_padded = np.zeros((image.shape[0] + window - 1, image.shape[1] + window - 1))\n",
    "    image_padded[\n",
    "        (window - 1) // 2 : -(window - 1) // 2, (window - 1) // 2 : -(window - 1) // 2\n",
    "    ] = image\n",
    "\n",
    "    result = np.zeros_like(image)\n",
    "\n",
    "    for i in range(0, image.shape[1]):\n",
    "        for j in range(0, image.shape[0]):\n",
    "            result[j, i] = (kernel * image_padded[j : j + window, i : i + window]).sum()\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def bilateral_convolution(image, W: int, sigma: float, noise_param: float):\n",
    "    kernel = fgaussian(W, sigma)\n",
    "    height, width = image.shape\n",
    "    result = np.zeros((height, width))\n",
    "    size = W // 2\n",
    "    gauss = fgaussian(W, sigma)\n",
    "    for i in range(size, height - size):\n",
    "        for j in range(size, width - size):\n",
    "            context = image[i - size : i + size + 1, j - size : j + size + 1]\n",
    "            W_n = 0\n",
    "            new_value = 0\n",
    "            for x in range(W):\n",
    "                for y in range(W):\n",
    "                    light_diff = np.abs(int(context[x, y]) - int(image[i, j])).astype(\n",
    "                        np.int8\n",
    "                    )\n",
    "                    temp = (\n",
    "                        np.exp((-1) * (((light_diff) ** 2) / (2 * (noise_param**2))))\n",
    "                        * gauss[x, y]\n",
    "                    )\n",
    "                    W_n += temp\n",
    "                    new_value += temp * context[x, y]\n",
    "            new_value = new_value / W_n if W_n != 0 else 0\n",
    "            result[i, j] = new_value\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 4, figsize=(20, 25))\n",
    "\n",
    "for i, img in enumerate(\n",
    "    [\"I_noisefree\", \"I_noisy1\", \"I_noisy2\", \"I_noisy3\", \"I_noisy4\"]\n",
    "):\n",
    "    # for i, fileName in enumerate([\"I_noisefree\"]):\n",
    "    img = mat[img]\n",
    "    axs[i, 0].imshow(img, \"gray\")\n",
    "    axs[i, 0].set_title(\"Orginal\")\n",
    "    axs[i, 1].imshow(classic_convolution(img, 5, 8), \"gray\")\n",
    "    axs[i, 1].set_title(\"Classic convolution\")\n",
    "    axs[i, 2].imshow(bilateral_convolution(img, 5, 8, 20), \"gray\")\n",
    "    axs[i, 2].set_title(\"Bilateral convolution\")\n",
    "    axs[i, 3].imshow(non_local_means(img, 11, 5, 0.5, 8), \"gray\")\n",
    "    axs[i, 3].set_title(\"Non-local means\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
